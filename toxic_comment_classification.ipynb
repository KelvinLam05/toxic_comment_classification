{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Goal of the project**","metadata":{}},{"cell_type":"markdown","source":"In this notebook, we will classify Wikipedia comments into one or more categories of so-called toxic comments. Categories of toxic online behavior include toxic, severe_toxic, obscene, threat, insult, and identity_hate. The dataset can be downloaded from the [Kaggle Toxic Comment Classification Challenge](https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge) as a CSV file (i.e., download the file train.csv).","metadata":{}},{"cell_type":"code","source":"# Importing libraries\nimport pandas as pd\nimport numpy as np\nimport ktrain\nimport tensorflow as tf\nfrom ktrain import text","metadata":{"id":"VXBR8Gr3FNZp","execution":{"iopub.status.busy":"2022-07-24T11:53:14.985671Z","iopub.execute_input":"2022-07-24T11:53:14.986471Z","iopub.status.idle":"2022-07-24T11:53:22.804922Z","shell.execute_reply.started":"2022-07-24T11:53:14.986422Z","shell.execute_reply":"2022-07-24T11:53:22.803538Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**Preprocess data and build a text classification model**","metadata":{}},{"cell_type":"markdown","source":"We will load the data using the texts_from_csv function. This function expects one column to contain the texts of documents and one or more other columns to store the labels.","metadata":{}},{"cell_type":"code","source":"DATA_PATH = '../input/jigsaw-toxic-comment-classification-challenge/train.csv'\nNUM_WORDS = 50000\nMAXLEN = 150\n\n(x_train, y_train), (x_test, y_test), preproc = text.texts_from_csv(DATA_PATH, 'comment_text',\n                                                                    label_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'],\n                                                                    val_filepath = None, \n                                                                    max_features = NUM_WORDS, \n                                                                    maxlen = MAXLEN,\n                                                                    ngram_range = 1)","metadata":{"id":"lVOwmKIldcyi","execution":{"iopub.status.busy":"2022-07-24T11:53:22.807007Z","iopub.execute_input":"2022-07-24T11:53:22.808217Z","iopub.status.idle":"2022-07-24T11:53:46.786827Z","shell.execute_reply.started":"2022-07-24T11:53:22.808176Z","shell.execute_reply":"2022-07-24T11:53:46.784725Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"detected encoding: utf-8 (if wrong, set manually)\n['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n        toxic  severe_toxic  obscene  threat  insult  identity_hate\n94264       0             0        0       0       0              0\n38494       0             0        0       0       0              0\n40813       0             0        0       0       0              0\n143555      0             0        0       0       0              0\n97918       0             0        0       0       0              0\n['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n        toxic  severe_toxic  obscene  threat  insult  identity_hate\n106940      0             0        0       0       0              0\n108665      0             0        0       0       0              0\n105716      0             0        0       0       0              0\n359         0             0        0       0       0              0\n15297       0             0        0       0       0              0\nlanguage: en\nWord Counts: 197205\nNrows: 143613\n143613 train sequences\ntrain sequence lengths:\n\tmean : 67\n\t95percentile : 228\n\t99percentile : 569\nx_train shape: (143613,150)\ny_train shape: (143613, 6)\nIs Multi-Label? True\n15958 test sequences\ntest sequence lengths:\n\tmean : 67\n\t95percentile : 226\n\t99percentile : 552\nx_test shape: (15958,150)\ny_test shape: (15958, 6)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Call the print_text_classifiers to show the available text classification models\ntext.print_text_classifiers()","metadata":{"id":"_D8y68JIeL6V","execution":{"iopub.status.busy":"2022-07-24T11:53:46.789663Z","iopub.execute_input":"2022-07-24T11:53:46.790207Z","iopub.status.idle":"2022-07-24T11:53:46.797613Z","shell.execute_reply.started":"2022-07-24T11:53:46.790160Z","shell.execute_reply":"2022-07-24T11:53:46.796609Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"fasttext: a fastText-like model [http://arxiv.org/pdf/1607.01759.pdf]\nlogreg: logistic regression using a trainable Embedding layer\nnbsvm: NBSVM model [http://www.aclweb.org/anthology/P12-2018]\nbigru: Bidirectional GRU with pretrained fasttext word vectors [https://fasttext.cc/docs/en/crawl-vectors.html]\nstandard_gru: simple 2-layer GRU with randomly initialized embeddings\nbert: Bidirectional Encoder Representations from Transformers (BERT) from keras_bert [https://arxiv.org/abs/1810.04805]\ndistilbert: distilled, smaller, and faster BERT from Hugging Face transformers [https://arxiv.org/abs/1910.01108]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Next, we load a text classification model and wrap the model and data in Learner object. ","metadata":{}},{"cell_type":"code","source":"model = text.text_classifier('fasttext', (x_train, y_train), preproc = preproc)","metadata":{"id":"Ix-uHdTDfRx-","execution":{"iopub.status.busy":"2022-07-24T11:53:46.799356Z","iopub.execute_input":"2022-07-24T11:53:46.799683Z","iopub.status.idle":"2022-07-24T11:53:55.089160Z","shell.execute_reply.started":"2022-07-24T11:53:46.799647Z","shell.execute_reply":"2022-07-24T11:53:55.087395Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Is Multi-Label? True\ncompiling word ID features...\nmaxlen is 150\ndone.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Wrap model and data in ktrain.Learner object\nlearner = ktrain.get_learner(model, train_data = (x_train, y_train), val_data = (x_test, y_test), batch_size = 16)","metadata":{"id":"jHBvvSyBfoL9","execution":{"iopub.status.busy":"2022-07-24T11:53:55.090663Z","iopub.execute_input":"2022-07-24T11:53:55.091009Z","iopub.status.idle":"2022-07-24T11:53:55.156220Z","shell.execute_reply.started":"2022-07-24T11:53:55.090972Z","shell.execute_reply":"2022-07-24T11:53:55.155258Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**Estimate a good learning rate**","metadata":{}},{"cell_type":"markdown","source":"To train the model, we will first find the optimal learning rate that suits well to our problem. ktrain provides a very good method named lr_find which trains the model at different learning rates and plots loss of the model as the learning rate is increased.","metadata":{}},{"cell_type":"code","source":"# Briefly simulate training to find good learning rate\nlearner.lr_find(max_epochs = 3) ","metadata":{"id":"P-FFPVetfts2","execution":{"iopub.status.busy":"2022-07-24T11:53:55.157604Z","iopub.execute_input":"2022-07-24T11:53:55.157949Z","iopub.status.idle":"2022-07-24T11:55:57.359858Z","shell.execute_reply.started":"2022-07-24T11:53:55.157913Z","shell.execute_reply":"2022-07-24T11:55:57.358790Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"simulating training for different learning rates... this may take a few moments...\nEpoch 1/3\n8976/8976 [==============================] - 45s 5ms/step - loss: 0.6720 - accuracy: 0.1934\nEpoch 2/3\n8976/8976 [==============================] - 43s 5ms/step - loss: 0.1241 - accuracy: 0.7062\nEpoch 3/3\n8976/8976 [==============================] - 34s 4ms/step - loss: 9.3041 - accuracy: 0.8787\n\n\ndone.\nPlease invoke the Learner.lr_plot() method to visually inspect the loss plot to help identify the maximal learning rate associated with falling loss.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The learning rate plot can be observed by calling the following method:","metadata":{}},{"cell_type":"code","source":"# Visually identify best learning rate\nlearner.lr_plot(suggest = True)","metadata":{"id":"w26glvwXfwqx","execution":{"iopub.status.busy":"2022-07-24T11:55:57.361375Z","iopub.execute_input":"2022-07-24T11:55:57.361719Z","iopub.status.idle":"2022-07-24T11:57:59.767901Z","shell.execute_reply.started":"2022-07-24T11:55:57.361682Z","shell.execute_reply":"2022-07-24T11:57:59.767010Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Three possible suggestions for LR from plot:\n\tLongest valley (red): 7.48E-05\n\tMin numerical gradient (purple): 4.55E-05\n\tMin loss divided by 10 (omitted from plot): 2.37E-03\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoFUlEQVR4nO3deXxcdb3/8ddnJpM9TZektLRp05ZWLFCWhqUimyy3LLf1KhVUEJRLRcUF0d+Fn16u4vXq1R96VXCp6EVxKVi43oKFIgqC0kJT6EJbW7oATemSbmnS7Mnn98ectkNI0rTkzJJ5Px+PeXTmzJmTd/JI553v+Z45x9wdERHJXpFUBxARkdRSEYiIZDkVgYhIllMRiIhkORWBiEiWUxGIiGS5nFQHOFJlZWVeWVmZ6hgiIhll6dKlO929vLvnMq4IKisrqa6uTnUMEZGMYmav9fScdg2JiGQ5FYGISJYLtQjMbLqZrTWz9WZ2WzfPjzGzp8zsJTNbYWaXhZlHRETeKrQiMLMocA9wKTAZ+KCZTe6y2peBB939VOBq4Idh5RERke6FOSI4A1jv7hvdvRWYC8zsso4Dg4L7pcAbIeYREZFuhHnU0Chgc8LjGuDMLut8BXjCzD4NFAEXhZhHRES6kerJ4g8C97n7aOAy4H4ze0smM5ttZtVmVl1bW3tUX+i1Xft5bOVWdNptEZE3C7MItgAVCY9HB8sS3QA8CODui4B8oKzrhtx9jrtXuXtVeXm3n4c4rMdf3sYnfv0i+1s7jur1IiIDVZhFsASYaGbjzCyX+GTw/C7rvA5cCGBm7yReBEf3J/9hlBbEAKhragtj8yIiGSu0InD3duBmYCGwhvjRQavM7E4zmxGsditwo5ktB34LXO8h7bs5WASNKgIRkUShnmLC3RcAC7osuyPh/mrg7DAzHKARgYhI91I9WZw0g1QEIiLdypoiGFwYL4I9ja0pTiIikl6ypghGlhYwrCiXx17eluooIiJpJWuKIBoxbjx3PM+sq2XhKpWBiMgBGXc9grfjummVPLriDT716xe56vQKciJGa4eTGzVK8mNUlhUxrqyI8WVFDCnKTXVcEZGkyKoiKMiN8tsbz+KWB5bz8ItbyM2JEItGaOvopKGlnY7OQ0euDi6MMXZYEaUFMfJzIkTMDrv9aNTIy4kwtDCXEaX5lBbEKM7LIT8WpTA3SnF+DiV5MYrzcyjOyyE3J2sGZCKSxrKqCABK8mPce13VW5a3dXRSs6eJTTsb2Fi7n0079/P67kbqmtrY3odPIztOe6fT0tbJrv0tNLd1HvY1uTkRSvJyDhZDcV4OJfkxhhXlMqw4l7LiPMpK8ig7cL84j8EFMSKRw5eSiEhfZV0R9CQWjTAu2DX0nuPf3rbcnX1N7exrbqO+uZ2W9g6aWjuob2mnobmdhpb4rb65nYaWtoPL6pvb2bK3iRU1e9m1v/VNI5QDohFjaNGBYsilvDjvUGkE948dXMC4siJiUY04ROTwVAQhMDNKC2OUBoesHo3OTqeuqY2dDS3UNrSwq6GVnQ0t7Ey4X9vQysba/exsaKGl/c0jkFjUGF9WzKQRJbzjmGImHVPC8SMGMXpIgUYUIvImKoI0FYkYQ4pyGVKUy8RjSnpd193Z39rBzvoWdu1vYfPuJtZur2fdtnpeen0Pjyw/dJmHgliUSUExnHDsIKoqh3L8iBJyNHoQyVoqggHAzA7OMVSWFTF17Jufb2hp55Xt9azbXs/abQ2s217PU2tr+d3SGiBeDqdUDKaqcginjR3CaWOGHDwlh4gMfCqCLFCcl8OpY4Zw6pghb1r+xt4mlr625+Dth09voKPTiRicNmYIFxw/nPMmlXPCsYOwPhw1JSKZyTLtQi1VVVVeXV2d6hgD0v6WdpbX7GXRhl08vbaWlVvqABhZms/0E0dw2UkjmTpmiOYYRDKQmS1197ceMomKQHqxo76Zv6yt5YnV2/nLulpa2zsZXpLHpSeO4B9PPpapY4dopCCSIVQE8rY1tLTzpzXbeWzlNp5au4OW9k7eOXIQ100by8xTRlGQG011RBHphYpA+tX+lnYeWf4G9z33Kn/fVs/gwhhXVVVw/dmVjCwtSHU8EemGikBC4e68sGk3v1j0KgtXbSdicOXU0dx03gTGDitKdTwRSdBbEeioITlqZsaZ44dx5vhhbN7dyE+e2cCD1TU8sGQzM08ZxecvnkTF0MJUxxSRw9CIQPrVjn3N/PTZjfxy0Wu4w0emjeXm9xzH4EKdzVUklbRrSJJua10T3/3jOn63tIaSvBw+dcFxfPTscTrjqkiK9FYEof6vNLPpZrbWzNab2W3dPP9dM1sW3NaZ2d4w80jyjCwt4FtXnsxjnz2HqWOH8I3H/s4VP3iWF1/fk+poItJFaCMCM4sC64CLgRpgCfBBd1/dw/qfBk5194/1tl2NCDLTk6u386//+zLb9jXzkbPG8sXpx1OcpykqkWRJ1YjgDGC9u29091ZgLjCzl/U/CPw2xDySQhdNPoY/fv48rptWyS8Xv8Yl3/kLizbsSnUsESHcIhgFbE54XBMsewszGwuMA/7cw/OzzazazKpra2v7PagkR3FeDl+ZcQIPfeJd5MeifOjexfzn43+nrePwF/ERkfCky8zd1cA8d+/2UmDuPsfdq9y9qry8PMnRpL+dNmYIj37m3VxVVcGPnt7A+3/0HJt27k91LJGsFeZO2i1ARcLj0cGy7lwNfCrELJJmCnNz+Ob7p3DepHJue3gll3//Wb464wRmVVWwe8NuFt21iBW/WkFrQyu5xblMuWYK026dxtAJQ1MdXWTACXOyOIf4ZPGFxAtgCfAhd1/VZb3jgceBcd6HMJosHni21jVxywPLWLxxNx+J5ZH/nRfoaOugM+G6z5FYhGgsyqx5s5h46cQUphXJTCmZLHb3duBmYCGwBnjQ3VeZ2Z1mNiNh1auBuX0pARmYRpYW8KsbzmT2xOF0fnMRbY1tbyoBgM62Ttoa2/jdlb9j94bdKUoqMjCFevyeuy8AFnRZdkeXx18JM4NkhpxohJOX7qCa3v8e6GjrYPF3F3PZ3ZclKZnIwJcuk8UirPjVCmjvvQg62zpZcf+KJCUSyQ4qAkkbrQ2t/bqeiPSNikDSRm5x305M19f1RKRvVASSNqZcM4VIrPdfyUgswpRrpyQpkUh2UBFI2ph26zSisd4veRmNRTnrlrOSlEgkO6gIJG0MnTCUWfNmESuMvWVkEIlFiBXGmDVvlj5UJtLPVASSViZeOpGbVtzE1NlTiRTFcCBWksvU2VO5acVN+jCZSAh0HmBJO0MnDOWyuy+j5YYp3PLAcp76wvmMK9M1kEXCohGBpK2IGQCd+tC5SKhUBJK2DhZBp4pAJEwqAklb0ciBEUGKg4gMcCoCSVtBD9ChJhAJlYpA0pbmCESSQ0UgaUtFIJIcKgJJW5ojEEkOFYGkLdMcgUhSqAgkbR0YEejidSLhUhFI2jowR6ARgUi4VASStg5NFqc4iMgAF2oRmNl0M1trZuvN7LYe1vmAma02s1Vm9psw80hmOfA5Ah01JBKu0E46Z2ZR4B7gYqAGWGJm8919dcI6E4HbgbPdfY+ZDQ8rj2SeQ0cNqQhEwhTmiOAMYL27b3T3VmAuMLPLOjcC97j7HgB33xFiHskwpjkCkaQIswhGAZsTHtcEyxJNAiaZ2d/MbLGZTe9uQ2Y228yqzay6trY2pLiSbg4dNZTiICIDXKoni3OAicD5wAeBn5rZ4K4rufscd69y96ry8vLkJpSU0bmGRJIjzCLYAlQkPB4dLEtUA8x39zZ33wSsI14MIjrFhEiShFkES4CJZjbOzHKBq4H5Xdb5PfHRAGZWRnxX0cYQM0kGURGIJEdoReDu7cDNwEJgDfCgu68yszvNbEaw2kJgl5mtBp4Cvujuu8LKJJlF5xoSSY5Qr1ns7guABV2W3ZFw34HPBzeRN9EcgUhypHqyWKRHEX2OQCQpVASStjRHIJIcKgJJW9GDF69PcRCRAU5FIGnr4PUINCIQCZWKQNKWrkcgkhwqAklbh65HkOIgIgOcikDSViT47dRksUi4VASStnTUkEhyqAgkbR06akhFIBImFYGkrYNzBOoBkVCpCCRtHZgj0FFDIuFSEUjaiugKZSJJoSKQtKWzj4okh4pA0taBTxbrqCGRcKkIJG3pqCGR5FARSNo6dNSQikAkTCoCSVsRzRGIJIWKQNJaxLRrSCRsKgJJa9GIabJYJGShFoGZTTeztWa23sxu6+b5682s1syWBbd/DjOPZB4z0xyBSMhCu3i9mUWBe4CLgRpgiZnNd/fVXVZ9wN1vDiuHZLaoGeoBkXCFOSI4A1jv7hvdvRWYC8wM8evJABQxfbJYJGxhFsEoYHPC45pgWVfvN7MVZjbPzCpCzCMZKKI5ApHQpXqy+BGg0t2nAH8EftHdSmY228yqzay6trY2qQEltSJmOmpIJGRhFsEWIPEv/NHBsoPcfZe7twQP7wWmdrchd5/j7lXuXlVeXh5KWElP8aOGUp1CZGALswiWABPNbJyZ5QJXA/MTVzCzkQkPZwBrQswjGShi+mSxSNhCO2rI3dvN7GZgIRAFfu7uq8zsTqDa3ecDnzGzGUA7sBu4Pqw8kpkiZroegUjIQisCAHdfACzosuyOhPu3A7eHmUEyW8RMRw2JhCzVk8UivYqYzjUkEjYVgaS1SERHDYmETUUgaS1i+hyBSNhUBJLWohGjQz0gEqo+FYGZfdbMBlncz8zsRTO7JOxwIma6VKVI2Po6IviYu+8DLgGGANcC3wwtlUggqk8Wi4Sur0UQXEacy4D73X1VwjKR0OREI7Rp35BIqPpaBEvN7AniRbDQzEqAzvBiicTlRo32Tv2qiYSprx8ouwE4Bdjo7o1mNhT4aGipRALxEYGKQCRMfR0RTAPWuvteM7sG+DJQF14skbhY1LRrSCRkfS2CHwGNZnYycCuwAfhlaKlEAjGNCERC19ciaPf4mb9mAne7+z1ASXixROJi0QjtGhGIhKqvcwT1ZnY78cNGzzGzCBALL5ZIXE7ENCIQCVlfRwRXAS3EP0+wjfhFZr4dWiqRQCxHu4ZEwtanIgje/H8NlJrZFUCzu2uOQEIXi2iyWCRsfT3FxAeAF4BZwAeA583syjCDiUD88NF2jQhEQtXXOYIvAae7+w4AMysHngTmhRVMBOKTxa0aEYiEqq9zBJEDJRDYdQSvFTlqMX2yWCR0fR0RPG5mC4HfBo+vosslKEXCEItGaGtXEYiEqU9F4O5fNLP3A2cHi+a4+/+EF0skLidqtOnsoyKh6vPuHXd/yN0/H9z6VAJmNt3M1prZejO7rZf13m9mbmZVfc0j2SFXnywWCV2vIwIzqwe6+3PMAHf3Qb28NgrcA1wM1ABLzGy+u6/usl4J8Fng+SPMLlkgJxLBHTo6nWhEZz4XCUOvIwJ3L3H3Qd3cSnorgcAZwHp33+jurcBc4qeo6OprwH8CzUf1HciAFsuJv/lrVCASnjCP/BkFbE54XBMsO8jMTgMq3P0PvW3IzGabWbWZVdfW1vZ/UklbsUj8V1RFIBKelB0CGpyv6DvEz2baK3ef4+5V7l5VXl4efjhJG7HogRGBJoxFwhJmEWwBKhIejw6WHVACnAg8bWavAmcB8zVhLInyYlEAWto7UpxEZOAKswiWABPNbJyZ5QJXA/MPPOnude5e5u6V7l4JLAZmuHt1iJkkwxTmxougsVVFIBKW0IrA3duBm4GFwBrgQXdfZWZ3mtmMsL6uDCwFwYigSUUgEpq+frL4qLj7Arp8Atnd7+hh3fPDzCKZqSAYETS1qQhEwqLzBUla064hkfCpCCStFcTig1btGhIJj4pA0tqhXUPtKU4iMnCpCCStadeQSPhUBJLWDo4IVAQioVERSForDA4frW/WriGRsKgIJK3lRCOUFsTY29ia6igiA5aKQNLe0KJcdje2pTqGyIClIpC0N6Qwxp79GhGIhEVFIGlvaFEeu1QEIqFREUjaG1oUY1dDS6pjiAxYKgJJexVDCtlR30Jjq44cEgmDikDS3nHDiwHYsGN/ipOIDEwqAkl7E48pAWDN1n0pTiIyMKkIJO1NKC+ivCSPJ1ZvS3UUkQFJRSBpz8z40BljeHLNDl56fU+q44gMOCoCyQizzx1PWXEe/7FgDe66kL1If1IRSEYoysvhcxdNZMmre/jj6u2pjiMyoKgIJGNcdXoF48uKuOuJdXR0alQg0l9CLQIzm25ma81svZnd1s3zN5nZSjNbZmZ/NbPJYeaRzBaLRrjl4kms3V7PoyveSHUckQEjtCIwsyhwD3ApMBn4YDdv9L9x95Pc/RTgW8B3wsojA8PlJ43k+BEl/NeTr9De0ZnqOCIDQpgjgjOA9e6+0d1bgbnAzMQV3D3xwPAiQON96VUkYtx6yTvoeGU9r151PQwaBJFI/N9PfhI2bEh1RJGME2YRjAI2JzyuCZa9iZl9ysw2EB8RfKa7DZnZbDOrNrPq2traUMJK5rjo1aU8cd+nGfs/v4H6enCP/3vvvTBlCjz2WKojimSUlE8Wu/s97j4B+Bfgyz2sM8fdq9y9qry8PLkBJb1s2IDNmkV+azOxzi6Xr2xrg8ZGuPJKjQxEjkCYRbAFqEh4PDpY1pO5wHtDzCMDwV13xd/we9PWBt/9bnLyiAwAYRbBEmCimY0zs1zgamB+4gpmNjHh4eXAKyHmkYHgV7/qWxHcf39y8ogMADlhbdjd283sZmAhEAV+7u6rzOxOoNrd5wM3m9lFQBuwB7gurDwyQDQ09O96IhJeEQC4+wJgQZdldyTc/2yYX18GoOLi+MRwX9YTkT5J+WSxyBG55hqIxXpfJxaDa69NTh6RAUBFIJnl1lv7VgS33JKcPCIDgIpAMsuECTBvHhQWvqUQWiNROgoK4s9PmJCigCKZR0UgmefSS2HFCpg9++Ani33QIB498wqu+cwcmi68JNUJRTKKikAy04QJcPfdUFcHHR1YXR0j7/8ZixjC/3tibarTiWQUFYEMGNMmDOOas8bw879tYv5ynZ1UpK9UBDKgfPnyyZxeOZRbH1zGc+t3pjqOSEZQEciAkh+L8tOPVDGurIibfrWUjbX6YJnI4agIZMApLYjxs+tOJyca4Z9/UU1d02FOSSGS5VQEMiBVDC3kRx8+jdd3N/K5uS/p0pYivVARyIB15vhh/Ns/TuaptbV85486kkikJ6Gea0gk1a45ayyr3tjHPU9toKw4j4+ePS7VkUTSjopABjQz46szT2D3/la++shqdu9v5fMXT8LMUh1NJG1o15AMeHk5UX744dO4+vQKfvDn9Xzt0TW4a85A5ACNCCQr5EQjfON9J1GQG+Xnf9tETtS4/dLjNTIQQUUgWcTMuOOKybR3OHOe2Ug0Yvyff3iHykCynopAsoqZ8dUZJ9Dhzo+e3sC2uma+8b6TyI9FUx1NJGVUBJJ1IhHj6+89kZGD8rnrj+tYt72eH18zlYqhhamOJpISmiyWrGRmfPrCifzsuipe393I5d9/lrkvvE6nPngmWSjUIjCz6Wa21szWm9lt3Tz/eTNbbWYrzOxPZjY2zDwiXV34zmN45OZ3c/yIQdz28Equ/PFzvLylLtWxRJIqtCIwsyhwD3ApMBn4oJlN7rLaS0CVu08B5gHfCiuPSE8qy4p44ONn8e0rp/Darkb+8e6/cttDK9jZ0JLqaCJJEeaI4AxgvbtvdPdWYC4wM3EFd3/K3RuDh4uB0SHmEemRmTGrqoKnvng+N5w9jnlLa7jg209z77MbaevoTHU8kVCFWQSjgM0Jj2uCZT25AXgsxDwihzUoP8aXr5jM4587l9PGDuHf/7CGK77/VxZv3JXqaCKhSYvJYjO7BqgCvt3D87PNrNrMqmtra5MbTrLSccOLue+jpzPn2qk0tLRz9ZzFfOa3L7F5d+PhXyySYcIsgi1ARcLj0cGyNzGzi4AvATPcvdudsu4+x92r3L2qvLw8lLAiXZkZl5wwgic/fx6fuXAij6/axnvuepov/34l2+qaUx1PpN9YWOdcMbMcYB1wIfECWAJ8yN1XJaxzKvFJ4unu/kpftltVVeXV1dUhJBbp3da6Ju7+83oerN6MmfHhM8fwifMnMLwkP9XRRA7LzJa6e1W3z4V58i0zuwz4LyAK/Nzdv25mdwLV7j7fzJ4ETgK2Bi953d1n9LZNFYGk2ubdjfzgz6/w0ItbiEWN66ZV8vHzJjC0KDfV0UR6lLIiCIOKQNLFpp37+f6fXuH3y7ZQGIvy0bPHceM54yktjKU6mshbqAhEQrR+Rz3fffIV/rBiKyV5OVx1egUfmVbJmGE6ZYWkDxWBSBKs2bqPHz69gcdWbqXTnUtPGslN507gpNGlqY4moiIQSaZtdc3c99yr/Hrxa9S3tHP2ccP4+LkTOGdimU55LSmjIhBJgX3Nbfz2+df52V83saO+hfHlRXz4zLFcOXU0pQWaR5DkUhGIpFBLewePLt/Kr55/jZde30t+LMJ7TxnFtdPGcsKx2m0kyaEiEEkTL2+p4/5Fr/G/y7fQ3NbJSaNKef9po5hxyigdfiqhUhGIpJm6xjbmvVjDQ0trWL11H7Gocd6k4Vw+ZQQXvvMYBuVr15H0LxWBSBpbs3UfD79YwyPLt7JtXzO50QhnHzeM8yaVM21CGZOOKdYks7xtKgKRDNDZ6Syr2cuCFVtZuHobm3c3AVBWnMuZ44fxrgnDmDZ+GOPKilQMcsRUBCIZaPPuRhZt3MWiDbt4bsNOtu+Ln5OxvCSPM8YN5axxQzlj3DAmDi8mElExDARtHZ3s2d9KbUMLOxtaqa1vYc/+Vhpa2mlq6+AfThjB1LFDjmrbvRWBLl4vkqYqhhZSMbSQD1RV4O5s2rmfRRt38cKm3Ty/cTd/WBE/RVdpQYyqsUOoqhxKVeUQTjy2lILcaIrTp5/OTqe1o5OW9k5a2jtoaeukua2DxtYOmto6cIdoxDCD/S3t7Gtup66xlea2Tto7nfaOTlqDW0eH097pdHQ6ne7kx6IU5kaJRSPkRA13aAq229TWQXPi/bYOmto6aTl4P56hua2Dto6e/zDPj0UYX1Z01EXQGxWBSAYwM8aXFzO+vJgPnzkWd2fz7iaWvLr74O1Pf98BxN/Mjisv5sRRpUwZXcqJo0qZPHJQVpfDtx7/Oz/76yZa2t/e1ebMiL/ZR4xocIuY0dLWQWNQJgdEDApzc8iPRciPRSmIRSnIjZIfi1JaECO/JI+8WJTCYHlBbnydIYUxykvyKCuO34YW51KUm0M0xFGfdg2JDBC7Glp48fW9rKzZy8otdazcUsfOhlYg/qY0cXgJxx1TzPiyIiqHFVFZVsT4siKGDKDDVhta2lm7bR+bdzdRs6eRzbubeHXXfp7ftJvpJ4xgSkUpeTlRcnMi5OVEKAzefPNjUSJmdHr8L/zC3CiD8mMMLsylIDd68I0/J2K9zs90dDptHZ2YQW40klZzOZojEMlC7s62fc2srKnj5aAYNu7cz+bdjXQm/LcvLYgxrqyIcUFBjCsvYtywIirLCilJ48NYG1raWbN1H6u21LFyyz5W1OxlfW3Dm/4qLyvOo2JoAadUDOb/XvZOYtG0uChjSqgIROSg1vZONu9p5NWd+9kU3F7dtZ9Ntft5o8uV18qK8xhXVkjlsCIqhhYyYlA+wwflccygfEYMymdwYSxpf/W2tHewblsDz23Yyf8ue4M12/YdfNMvK85lyujBTBldykmjShk7rJBRgwuzendYV5osFpGDcnMiTCgvZkJ58Vuea27r4LVdjWza2cCmnYfK4ul1tdTWv/VKsrnRCMMH5TG8JI/BhbkMys9h+KB8PnvhRIry3v7bS11TG4+t3MpDL9awbPPeg5Opp44ZzOcunMSJowZx4qhShpfkpdVumEyjIhCRg/JjUd4xooR3jCh5y3Mt7R3s2NfCjvpmttW1sH1fM9vrm9mxL35/R30za7a2srWumWnjh3HB8cOPKsOG2gaeXL2dv67fyfMbd9Pa0cnE4cV87N3jmDIq/ld/xVBd66E/qQhEpE/ycqIHD2ntycbaBt5z11/Y29R6xNv/2/qdfGX+Kl7Z0QDApGOKuXbaWGacfCxTRpfqL/4QqQhEpN8cOL12XWNbn1+zo76Zbz++lt8trWF8eRF3zjyBC995DKMGF4QVU7pQEYhIvxl0oAia2g+7bs2eRuY8s5EHlmym052PnzeeWy6aRH5ME7zJFmoRmNl04HtAFLjX3b/Z5flzgf8CpgBXu/u8MPOISLhi0QhFuVHqmnoeEexqaOEnz2zkv/+2CYD3nTqaT5w/gcqyomTFlC5CKwIziwL3ABcDNcASM5vv7qsTVnsduB74Qlg5RCS5BhfmHpwjaGhp5/5Fr7Fs8x5a2jt5fVcjG3fuxwxmTR3NLRdPYmSpdgGlWpgjgjOA9e6+EcDM5gIzgYNF4O6vBs+9vc99i0jaGFQQY19TG2/sbeITv36R5Zv3UjmskMLcHMaXFzGrqoILji/n+BGDUh1VAmEWwShgc8LjGuDMo9mQmc0GZgOMGTPm7ScTkdCUl+Tx5JodvLDpGTod5lw7lUtOGJHqWNKLjJgsdvc5wByIf7I4xXFEpBefOG8CDc1tFOXl8JUZJ3T7wTVJL2EWwRagIuHx6GCZiAxg0yYM4+FPnp3qGHIEwjwD0xJgopmNM7Nc4GpgfohfT0REjkJoReDu7cDNwEJgDfCgu68yszvNbAaAmZ1uZjXALOAnZrYqrDwiItK9UOcI3H0BsKDLsjsS7i8hvstIRERSJHtPzi0iIoCKQEQk66kIRESynIpARCTLqQhERLJcxl2z2MxqgdeCh6VAXS/3u/5bBuw8gi+XuM2+Pt91mTIqYzIy9vRcpmXsKW9vWcPO2NvPMJMyDnb38m636O4ZewPm9Ha/m3+rj3b7fX2+6zJlVMZkZOzpuUzL2FPew2QNNWNvP8NMy9jTLdN3DT1ymPtd/3072+/r812XKaMyJiNjT89lWsae8vaW9UgdacbefoY95UnXjN3KuF1Db4eZVbt7Vapz9EYZ+4cy9g9l7B/pnjHTRwRHak6qA/SBMvYPZewfytg/0jpjVo0IRETkrbJtRCAiIl2oCEREspyKQEQky6kIAmZ2jpn92MzuNbPnUp2nO2YWMbOvm9kPzOy6VOfpjpmdb2bPBj/L81OdpydmVmRm1WZ2RaqzdMfM3hn8DOeZ2SdSnac7ZvZeM/upmT1gZpekOk93zGy8mf3MzOalOssBwe/eL4Kf3YdTnQcGSBGY2c/NbIeZvdxl+XQzW2tm683stt624e7PuvtNwKPAL9IxIzCT+PUb2oCaNM3oQAOQn8YZAf4FeLC/8/VXRndfE/w+fgDo9+s+9lPG37v7jcBNwFVpmnGju9/Q39m6OsKs7wPmBT+7GWFn65Mj+bRbut6Ac4HTgJcTlkWBDcB4IBdYDkwGTiL+Zp94G57wugeBknTMCNwGfDx47bw0zRgJXncM8Os0zXgx8UunXg9ckY4Zg9fMAB4DPpSuGYPX3QWcluYZ+/3/y9vIejtwSrDOb8LM1ddbqFcoSxZ3f8bMKrssPgNY7+4bAcxsLjDT3b8BdLs7wMzGAHXuXp+OGYPLerYGDzvSMWOCPUBeOmYMdlkVEf9P2WRmC9y9M50yBtuZD8w3sz8Av+mvfP2V0cwM+CbwmLu/2J/5+itjshxJVuIj5dHAMtJkr8yAKIIejAI2JzyuAc48zGtuAP47tERvdaQZHwZ+YGbnAM+EGSzBEWU0s/cB/wAMBu4ONdkhR5TR3b8EYGbXAzv7swR6caQ/x/OJ70LIo8vlXkN0pL+PnwYuAkrN7Dh3/3GY4QJH+nMcBnwdONXMbg8KI1l6yvp94G4zu5yjPwVFvxrIRXDE3P3fUp2hN+7eSLys0pa7P0y8sNKeu9+X6gw9cfengadTHKNX7v594m9qacvddxGfw0gb7r4f+GiqcyRKi2FJSLYAFQmPRwfL0oky9g9l7B/K2L8yJutALoIlwEQzG2dmucQnB+enOFNXytg/lLF/KGP/ypysqZ6t7o8b8FtgK4cOq7whWH4ZsI74zP2XlFEZlVEZsz1rdzeddE5EJMsN5F1DIiLSByoCEZEspyIQEclyKgIRkSynIhARyXIqAhGRLKcikNCZWUMSvsZNZvaRsL9Ol6/5XjObfJSvuyO4/xUz+0L/pztyFr+WxKOHWeckM7svSZEkSXSuIckYZhZ1927PuuohnfCst68JvJf46Y5XH+Fm/w/pch76I+TuK81stJmNcffXU51H+odGBJJUZvZFM1tiZivM7KsJy39vZkvNbJWZzU5Y3mBmd5nZcmBa8PjrZrbczBab2THBegf/sjazp83sP83sBTNbF5ytFTMrNLMHzWy1mf2PmT1vZlXdZHw1eP2LwCwzuzHIvNzMHgq28y7ib+bfNrNlZjYhuD0efB/Pmtnx3Wx7EtDi7ju7ee6U4HtaEeQbEiw/PVi2zMy+bV0ufhKsM9LMngnWeTnhe55uZi8G2f8ULDvDzBaZ2Utm9pyZvaOb7RVZ/GIrLwTrzUx4+hHip0uQAUJFIElj8csZTiR+nvZTgKlmdm7w9MfcfSpQBXwmOH0wxK8b8Ly7n+zufw0eL3b3k4mfivvGHr5cjrufAXwOOHBW2U8Ce9x9MvCvwNRe4u5y99PcfS7wsLufHnzNNcRPH/Ac8fPGfNHdT3H3DcAc4NPB9/EF4IfdbPdsoKdz9/8S+Bd3nwKsTMj938QvSHQKPV+H4kPAwmCdk4FlZlYO/BR4f5B9VrDu34Fz3P1U4A7gP7rZ3peAPwc/wwuIF15R8Fw1cE4POSQDadeQJNMlwe2l4HEx8WJ4hvib/z8FyyuC5buIv/E9lLCNVuK7YwCWEr/aWHceTlinMrj/buB7AO7+spmt6CXrAwn3TzSzfyd+jYViYGHXlc2sGHgX8DszO7C4uwvzjARqu3l9KTDY3f8SLPpFsK3BxK+YtyhY/hu6vwDLEuDnZhYDfu/uyyx+TYNn3H0TgLvvDtYtBX5hZhOJX1o01s32LgFmJMxf5ANjiBfhDuDYbl4jGUpFIMlkwDfc/SdvWhh/w7oImObujWb2NPE3HoDmLvvo2/zQCbI66Pl3uKUP6/Rmf8L9+4D3uvtyi1/M5vxu1o8Ae4O/yHvTRPyNuF95/ApZ5wKXA/eZ2XeIXyWuO18DnnL3f7L4VbWe7mYdIz6SWNvNc/nEvw8ZILRrSJJpIfCx4K9nzGyUmQ0n/sa4JyiB44GzQvr6fyN+MXiCo31O6uPrSoCtwV/bH05YXh88h7vvAzaZ2axg+2ZmJ3ezrTXAcV0XunsdsOfAvn3gWuAv7r4XqDezA1fh6nbfvJmNBba7+0+Be4lfP3cxcK6ZjQvWGRqsXsqh8+Jf38P3vBD4tAXDGzM7NeG5ScBb5ikkc6kIJGnc/QniuzYWmdlKYB7xN9LHgRwzW0P8GriLQ4rwQ6DczFYD/w6sAur68Lp/BZ4nXiR/T1g+F/hiMJk6gXhJ3BBMbK8ifn3arp4hftlE6+a564jvi19BfA7lzmD5DcBPzWwZ8TmS7jKfDyw3s5eAq4DvuXstMBt4OMh0YHfXt4BvBOv2NFr6GvFdRivMbFXw+IALgD/08DrJQDoNtWQNM4sCMXdvDt64nwTe4e6tSc7xPeARd3+yj+sXu3tDcP82YKS7fzbMjL1kyQP+Arzb3dtTkUH6n+YIJJsUAk8Fu3gM+GSySyDwH/R+UfiuLjez24n/f32NnnfnJMMY4DaVwMCiEYGISJbTHIGISJZTEYiIZDkVgYhIllMRiIhkORWBiEiWUxGIiGS5/w8nC6K4j0kfFgAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"We will now train the model using the autofit method. The method trains the classifier and automatically selects the best performing one preventing underfitting and overfitting of the model.","metadata":{}},{"cell_type":"code","source":"# Training using the autofit policy\nlearner.autofit(7.48E-05, early_stopping = 5)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T11:58:21.449691Z","iopub.execute_input":"2022-07-24T11:58:21.450809Z","iopub.status.idle":"2022-07-24T12:34:22.078651Z","shell.execute_reply.started":"2022-07-24T11:58:21.450763Z","shell.execute_reply":"2022-07-24T12:34:22.077537Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"reduce_on_plateau automatically enabled at patience=2\n\n\nbegin training using triangular learning rate policy with max lr of 7.48e-05...\nEpoch 1/1024\n8976/8976 [==============================] - 53s 6ms/step - loss: 0.2842 - accuracy: 0.3348 - val_loss: 0.1036 - val_accuracy: 0.9437\nEpoch 2/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.1179 - accuracy: 0.6135 - val_loss: 0.0724 - val_accuracy: 0.9877\nEpoch 3/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.0934 - accuracy: 0.7781 - val_loss: 0.0614 - val_accuracy: 0.9928\nEpoch 4/1024\n8976/8976 [==============================] - 53s 6ms/step - loss: 0.0811 - accuracy: 0.8938 - val_loss: 0.0568 - val_accuracy: 0.9931\nEpoch 5/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.0751 - accuracy: 0.9489 - val_loss: 0.0560 - val_accuracy: 0.9932\nEpoch 6/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.0703 - accuracy: 0.9736 - val_loss: 0.0551 - val_accuracy: 0.9932\nEpoch 7/1024\n8976/8976 [==============================] - 50s 6ms/step - loss: 0.0681 - accuracy: 0.9829 - val_loss: 0.0543 - val_accuracy: 0.9932\nEpoch 8/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.0652 - accuracy: 0.9884 - val_loss: 0.0539 - val_accuracy: 0.9932\nEpoch 9/1024\n8976/8976 [==============================] - 50s 6ms/step - loss: 0.0638 - accuracy: 0.9912 - val_loss: 0.0531 - val_accuracy: 0.9932\nEpoch 10/1024\n8976/8976 [==============================] - 50s 6ms/step - loss: 0.0619 - accuracy: 0.9924 - val_loss: 0.0528 - val_accuracy: 0.9932\nEpoch 11/1024\n8976/8976 [==============================] - 51s 6ms/step - loss: 0.0604 - accuracy: 0.9931 - val_loss: 0.0533 - val_accuracy: 0.9932\nEpoch 12/1024\n8976/8976 [==============================] - 51s 6ms/step - loss: 0.0598 - accuracy: 0.9934 - val_loss: 0.0525 - val_accuracy: 0.9932\nEpoch 13/1024\n8976/8976 [==============================] - 51s 6ms/step - loss: 0.0587 - accuracy: 0.9938 - val_loss: 0.0527 - val_accuracy: 0.9932\nEpoch 14/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.0581 - accuracy: 0.9937 - val_loss: 0.0521 - val_accuracy: 0.9932\nEpoch 15/1024\n8976/8976 [==============================] - 51s 6ms/step - loss: 0.0572 - accuracy: 0.9940 - val_loss: 0.0522 - val_accuracy: 0.9932\nEpoch 16/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.0561 - accuracy: 0.9939 - val_loss: 0.0521 - val_accuracy: 0.9932\nEpoch 17/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.0553 - accuracy: 0.9940 - val_loss: 0.0520 - val_accuracy: 0.9932\nEpoch 18/1024\n8976/8976 [==============================] - 53s 6ms/step - loss: 0.0548 - accuracy: 0.9942 - val_loss: 0.0520 - val_accuracy: 0.9932\nEpoch 19/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.0545 - accuracy: 0.9941 - val_loss: 0.0519 - val_accuracy: 0.9932\nEpoch 20/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.0540 - accuracy: 0.9941 - val_loss: 0.0518 - val_accuracy: 0.9932\nEpoch 21/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.0535 - accuracy: 0.9942 - val_loss: 0.0524 - val_accuracy: 0.9932\nEpoch 22/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.0529 - accuracy: 0.9942 - val_loss: 0.0519 - val_accuracy: 0.9932\n\nEpoch 00022: Reducing Max LR on Plateau: new max lr will be 3.74e-05 (if not early_stopping).\nEpoch 23/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.0525 - accuracy: 0.9942 - val_loss: 0.0517 - val_accuracy: 0.9932\nEpoch 24/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.0518 - accuracy: 0.9942 - val_loss: 0.0516 - val_accuracy: 0.9932\nEpoch 25/1024\n8976/8976 [==============================] - 51s 6ms/step - loss: 0.0519 - accuracy: 0.9942 - val_loss: 0.0518 - val_accuracy: 0.9932\nEpoch 26/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.0515 - accuracy: 0.9941 - val_loss: 0.0514 - val_accuracy: 0.9932\nEpoch 27/1024\n8976/8976 [==============================] - 51s 6ms/step - loss: 0.0510 - accuracy: 0.9940 - val_loss: 0.0520 - val_accuracy: 0.9932\nEpoch 28/1024\n8976/8976 [==============================] - 51s 6ms/step - loss: 0.0510 - accuracy: 0.9941 - val_loss: 0.0520 - val_accuracy: 0.9932\n\nEpoch 00028: Reducing Max LR on Plateau: new max lr will be 1.87e-05 (if not early_stopping).\nEpoch 29/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.0506 - accuracy: 0.9942 - val_loss: 0.0516 - val_accuracy: 0.9932\nEpoch 30/1024\n8976/8976 [==============================] - 51s 6ms/step - loss: 0.0506 - accuracy: 0.9941 - val_loss: 0.0520 - val_accuracy: 0.9932\n\nEpoch 00030: Reducing Max LR on Plateau: new max lr will be 9.35e-06 (if not early_stopping).\nEpoch 31/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.0506 - accuracy: 0.9941 - val_loss: 0.0513 - val_accuracy: 0.9932\nEpoch 32/1024\n8976/8976 [==============================] - 51s 6ms/step - loss: 0.0504 - accuracy: 0.9941 - val_loss: 0.0513 - val_accuracy: 0.9932\nEpoch 33/1024\n8976/8976 [==============================] - 51s 6ms/step - loss: 0.0502 - accuracy: 0.9941 - val_loss: 0.0517 - val_accuracy: 0.9932\nEpoch 34/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.0504 - accuracy: 0.9941 - val_loss: 0.0516 - val_accuracy: 0.9932\n\nEpoch 00034: Reducing Max LR on Plateau: new max lr will be 4.675e-06 (if not early_stopping).\nEpoch 35/1024\n8976/8976 [==============================] - 51s 6ms/step - loss: 0.0502 - accuracy: 0.9942 - val_loss: 0.0511 - val_accuracy: 0.9932\nEpoch 36/1024\n8976/8976 [==============================] - 51s 6ms/step - loss: 0.0501 - accuracy: 0.9941 - val_loss: 0.0515 - val_accuracy: 0.9932\nEpoch 37/1024\n8976/8976 [==============================] - 51s 6ms/step - loss: 0.0500 - accuracy: 0.9940 - val_loss: 0.0509 - val_accuracy: 0.9932\nEpoch 38/1024\n8976/8976 [==============================] - 51s 6ms/step - loss: 0.0500 - accuracy: 0.9941 - val_loss: 0.0518 - val_accuracy: 0.9932\nEpoch 39/1024\n8976/8976 [==============================] - 52s 6ms/step - loss: 0.0498 - accuracy: 0.9941 - val_loss: 0.0518 - val_accuracy: 0.9932\n\nEpoch 00039: Reducing Max LR on Plateau: new max lr will be 2.3375e-06 (if not early_stopping).\nEpoch 40/1024\n8976/8976 [==============================] - 50s 6ms/step - loss: 0.0503 - accuracy: 0.9941 - val_loss: 0.0516 - val_accuracy: 0.9932\nEpoch 41/1024\n8976/8976 [==============================] - 51s 6ms/step - loss: 0.0496 - accuracy: 0.9941 - val_loss: 0.0517 - val_accuracy: 0.9932\n\nEpoch 00041: Reducing Max LR on Plateau: new max lr will be 1.16875e-06 (if not early_stopping).\nEpoch 42/1024\n8976/8976 [==============================] - 51s 6ms/step - loss: 0.0499 - accuracy: 0.9942 - val_loss: 0.0513 - val_accuracy: 0.9932\nRestoring model weights from the end of the best epoch.\nEpoch 00042: early stopping\nWeights from best epoch have been loaded into model.\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f63833e9590>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Making predictions**","metadata":{}},{"cell_type":"code","source":"y_pred = learner.model.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-07-24T12:34:22.081831Z","iopub.execute_input":"2022-07-24T12:34:22.082111Z","iopub.status.idle":"2022-07-24T12:34:44.789347Z","shell.execute_reply.started":"2022-07-24T12:34:22.082086Z","shell.execute_reply":"2022-07-24T12:34:44.788057Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**Evaluate model**","metadata":{}},{"cell_type":"markdown","source":"Let's compute for ROC-AUC of our final model for identifying toxic online behavior:","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2022-07-24T12:34:44.791025Z","iopub.execute_input":"2022-07-24T12:34:44.791385Z","iopub.status.idle":"2022-07-24T12:34:44.798380Z","shell.execute_reply.started":"2022-07-24T12:34:44.791349Z","shell.execute_reply":"2022-07-24T12:34:44.797195Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Evaluate model\nscore = roc_auc_score(y_test, y_pred)\nprint(\"\\n ROC-AUC score: %.6f \\n\" % (score))","metadata":{"execution":{"iopub.status.busy":"2022-07-24T12:34:44.801235Z","iopub.execute_input":"2022-07-24T12:34:44.801717Z","iopub.status.idle":"2022-07-24T12:34:44.872004Z","shell.execute_reply.started":"2022-07-24T12:34:44.801679Z","shell.execute_reply":"2022-07-24T12:34:44.870873Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"\n ROC-AUC score: 0.974877 \n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Our final ROC-AUC score is **0.97**.","metadata":{}}]}